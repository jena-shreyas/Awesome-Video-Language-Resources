# Awesome Video Language Model Resources

This repo contains a collection of video language models-based works over the past few years that I found interesting. Hope this helps !

## Models

- [Towards Fast Adaptation of Pretrained Contrastive Models for Multi-channel Video-Language Retrieval](https://arxiv.org/abs/2206.02082) \[CVPR 2023\]\
Code : [https://github.com/XudongLinthu/upgradable-multimodal-intelligence](https://github.com/XudongLinthu/upgradable-multimodal-intelligence)

- [Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners](https://arxiv.org/abs/2205.10747.pdf) **(VidIL)** \[NeurIPS 2022\]\
Code : [https://github.com/MikeWangWZHL/VidIL](https://github.com/MikeWangWZHL/VidIL)

- [Invariant Grounding for Video Question Answering](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf)  **(IGV)** \[CVPR 2022\]\
Code : [https://github.com/yl3800/IGV](https://github.com/yl3800/IGV)

- [Video as Conditional Graph Hierarchy for Multi-Granular Question Answering](https://arxiv.org/abs/2112.06197) **(HQGA)** \[AAAI 2022\]\
Code : [https://github.com/doc-doc/HQGA](https://github.com/doc-doc/HQGA)


## Datasets

- [ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos](https://arxiv.org/abs/2311.01620) \[EMNLP 2023\] \
Code : [https://github.com/PlusLabNLP/acquired](https://github.com/PlusLabNLP/acquired) (NOT RELEASED YET)

- [From representation to reasoning: Towards both evidence and commonsense reasoning for video question-answering](https://arxiv.org/abs/2205.14895.pdf) **(CausalVidQA)** \[CVPR 2022\]\
Code : [https://github.com/bcmi/Causal-VidQA](https://github.com/bcmi/Causal-VidQA)

- [ComPhy: Compositional Physical Reasoning of Objects and Events from Videos
](https://arxiv.org/abs/2205.01089) **(ComPhy)** \[ICLR 2022\] \
Code : [https://github.com/zfchenUnique/compositional_physics_learner](https://github.com/zfchenUnique/compositional_physics_learner)

- [NExT-QA:Next Phase of Question-Answering to Explaining Temporal Actions](https://arxiv.org/abs/2105.08276.pdf) **(NeXT-QA)** \[CVPR 2021\] \
Code : [https://github.com/doc-doc/NExT-QA](https://github.com/doc-doc/NExT-QA)

- [CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions](https://arxiv.org/abs/2012.04293) **(CRAFT)** \[ACL 2022\] \
Code : [https://github.com/hucvl/craft](https://github.com/hucvl/craft)

- [CLEVRER: CoLlision Events for Video REpresentation and Reasoning
](https://arxiv.org/abs/1910.01442) **(CLEVRER)** \[ICLR 2020\] \
Code : [https://github.com/chuangg/CLEVRER](https://github.com/chuangg/CLEVRER)

## Summary papers

- [Video Question Answering: Datasets, Algorithms and Challenges](https://arxiv.org/abs/2203.01225.pdf)

